% $Header$

\documentclass{beamer}

\usepackage{amsmath,amssymb,latexsym,eucal,amsthm,graphicx}
\include{mathdefs}

\graphicspath{{images/}}

\newtheorem*{claim}{claim}
\newtheorem*{observation}{Observation}
\newtheorem*{warning}{Warning}
\newtheorem*{question}{Question}
\newtheorem{remark}[theorem]{Remark}

\newenvironment*{subproof}[1][Proof]
{\begin{proof}[#1]}{\renewcommand{\qedsymbol}{$\diamondsuit$} \end{proof}}

\mode<presentation>
{
  \usetheme{Singapore}
  % or ...

  \setbeamercovered{invisible}
  % or whatever (possibly just delete it)
}


\usepackage[english]{babel}
% or whatever

\usepackage[latin1]{inputenc}
% or whatever

\usepackage{times}
\usepackage[T1]{fontenc}
% Or whatever. Note that the encoding and the font should match. If T1
% does not look nice, try deleting the line with the fontenc.

\title{Lesson 4 \\ Linear functions $\R^n$}
\subtitle{Math 325, Linear Algebra \\ Fall 2018 \\ SFSU}
\author{Mitch Rudominer}
\date{}



% If you wish to uncover everything in a step-wise fashion, uncomment
% the following command:

\beamerdefaultoverlayspecification{<+->}

\begin{document}

\begin{frame}
  \titlepage
\end{frame}

\begin{frame}{Linear functions on $\R^n$}

\begin{itemize}
\item Now we begin the real material of Linear Algebra
\item We study the important concept of a \emph{linear function}
\item For now we only talk about linear functions from $\R^n$ to $\R^m$.
\item Later we will genearlize this to linear functions on \emph{vector spaces}.
\end{itemize}

\end{frame}

\begin{frame}{Linear functions on $\R^n$}

\begin{itemize}
\item Let $f:\R^n \map \R^m$.
\item $f$ is called \emph{linear} iff $f$ satisfies the following two properties:
\item (i) For every two vectors $\bv, \bw \in\R^n$, $$f(\bv + \bw) = f(\bv) + f(\bw)$$
\item (ii) For all vectors $\bv\in\R^n$ and all scalars $c\in \R$,
$$f(c \bv) = c f(\bv)$$
\item In short we say ``f preserves vector addition and scalar multiplication.''
\end{itemize}

\end{frame}

\begin{frame}{$f$ Preserves Addition}

\begin{center}
\includegraphics[scale=0.25]{preserving-addition}
\end{center}

\begin{itemize}
\item $f(\bv + \bw) = f(\bv) + f(\bw)$
\item Let $f(\bv) = \bv^{\prime}$.
\item Let $f(\bw) = \bw^{\prime}$.
\item We can compute a vector sum on the left: $\bv + \bw$.
\item We can compute a vector sum on the right: $\bv^{\prime} + \bw^{\prime}$.
\item $f$ must move the vector sum on the left to the vector sum on the right.
\end{itemize}

\end{frame}

\begin{frame}{$f$ Preserves Scalar Multiplication}

\begin{center}
\includegraphics[scale=0.25]{preserving-scalar-mult}
\end{center}

\begin{itemize}
\item $f(c \bv) = c f(\bv)$
\item Let $f(\bv) = \bv^{\prime}$.
\item Let $c = 2$.
\item We can compute a scalar multiplication on the left: $2 \bv$.
\item We can compute a scalar multiplication on the right: $2 \bv^{\prime}$.
\item $f$ must move the scalar multiple on the left to the scalar multiple on the right.
\end{itemize}

\end{frame}

\begin{frame}{Example 1. $f:\R^1\map\R^1$}

\begin{itemize}
\item Let $f:\R^1\map\R^1$ be given by $f(x) = x^2$.
\item Is $f$ linear?
\item Check: Does $f$ preserve vector addition?
\item Note that on $\R^1$ vector addition is just ordinary addition of numbers.
\item $f(x_1 + x_2) = (x_1 + x_2)^2$
\item $= x_1^2 + x_2^2 + 2 x_1 x_2$
\item $= f(x_1) + f(x_2) + 2 x_1 x_2$.
\item So $f(x_1 + x_2) \not= f(x_1) + f(x_2)$
\item unless $2 x_1 x_2 = 0$, i.e. unless $x_1 = 0$ or $x_2 = 0$.
\item So $f$ is \emph{not} linear.
\end{itemize}

\end{frame}

\begin{frame}{Example 1. $f:\R^1\map\R^1$}

\begin{itemize}
\item Continue to let $f:\R^1\map\R^1$ be given by $f(x) = x^2$.
\item We already know $f$ is not linear.
\item Just for fun, check: Does $f$ preserve scalar multiplication?
\item $f(c x) = (c x)^2$
\item $= c^2 x^2$
\item $= c^2 f(x)$.
\item So $f(c x) \not= c f(x)$
\item unless $c^2 = c$, i.e. unless $c=0, 1$.
\item So again, $f$ is not linear.
\end{itemize}

\end{frame}

\begin{frame}{Example 2. $f:\R^1\map\R^1$}

\begin{itemize}
\item Let $f:\R^1\map\R^1$ be given by $f(x) = 2 x$.
\item Is $f$ linear?
\item Check: Does $f$ preserve vector addition?
\item $f(x_1 + x_2) =  2(x_1 + x_2)$
\item $ = 2 x_1 + 2 x_2$
\item $= f(x_1) + f(x_2)$.
\item So $f$ \emph{does} preserve addition.
\item Check: Does $f$ preserve scalar multiplication?
\item $f(c x) = 2 (c x)$
\item $ = c (2 x) $
\item $= c f(x)$.
\item So $f$ does preserve scalar multiplication.
\item So $f$ is linear.
\end{itemize}

\end{frame}

\beamerdefaultoverlayspecification{}

\begin{frame}{Example 3. $f:\R^2\map\R^1$}

\begin{columns}

\column[T]{5cm}
\begin{itemize}
\item<1-> Consider this function from lesson 3:
\item<2-> $f(x,y) = x^2 + y$
\item<3-> Is $f$ linear?
\item<4-> Check: Does $f$ preserve vector addition?
\item<5-> Let $\bv, \bw \in \R^2$
\item<6-> We need to check if $f(\bv + \bw) = f(\bv) + f(\bw)$
\end{itemize}

\column[T]{5cm}
\includegraphics<2->[scale=0.15]{x-squared-plus-y}
\end{columns}

\end{frame}


\begin{frame}{Does $f$ preserve vector addtion?}
\begin{align*}
&f(\bv + \bw) \\
\uncover<2->{&=  f\bigl((v_1, v_2) + (w_1, w_2)\bigr) \\}
\uncover<3->{&= f\bigl(v_1 + w_1, v_2 + w_2\bigr) \\}
\uncover<4->{&= \bigl(v_1 + w_1 \bigr)^2 + (v_2 + w_2) \\}
\uncover<5->{&= (v_1^2 + 2 v_1 w_1 + w_1^2) + (v_2 + w_2) \\}
\uncover<6->{&= (v_1^2 + v_2) + (w_1^2 + w_2)  + 2v_1 w_1\\}
\uncover<7->{&= f(v_1, v_2) + f(w_1, w_2)  + 2v_1 w_1\\}
\uncover<8->{&= f(\bv) + f(\bw)  + 2v_1 w_1\\}
\uncover<9->{&\not= f(\bv) + f(\bw) \text{ unless $v_1=0$ or $w_1=0$}\\}
\end{align*}

\uncover<10->{So $f$ does not preserve vector addtion. So $f$ is not linear.}
\end{frame}

\beamerdefaultoverlayspecification{<+->}

\begin{frame}{Linear Functionals}

\begin{itemize}
\item A linear function from $\R^n$ to $\R^1$ is also called a linear
\emph{functional}.
\item Let $\bv \in \R^n$ be any vector.
\item We will show how $\bv$ can used as a linear functional.
\item In its role as a linear functional, $\bv$ is called a \emph{covector}.
\item Let $f_{\bv} : \R^n \map \R^1$ be defined by
$$f_{\bv}(\bw) = \bv \cdot \bw$$
\item $f_{\bv}$ is called the \emph{covector} associated to the vector $\bv$.
\end{itemize}

\end{frame}

\begin{frame}{Example Covector}

\begin{itemize}
\item Let $\bv = (2, -1)$
\item So $f_{\bv}:\R^2 \map \R$.
\item Let $\bw = (4, 5) \in \R^2$.
\item Compute $f_{\bv}(\bw)$
\item $= \bv \cdot \bw = 8 - 5 = 3$
\item $f_{\bv}(\bw) =  3$.
\end{itemize}

\end{frame}

\begin{frame}{Dot Product is Linear}

\begin{itemize}
\item Claim: For any vector $\bv\in\R^n$, $f_{\bv}:\R^n\map\R$ is linear.
\item proof:
\item First we show that $f_{\bv}$ preserves vector addition.
\item Let $\bu, \bw \in \R^n$
\item We must show $f_{\bv}(\bu + \bw) = f_{\bv}(\bu) + f_{\bv}(\bw)$
\item i.e. that $\bv \cdot (\bu + \bw) = \bv \cdot \bu + \bv \cdot \bw$.
\item This is just the distributive law for dot product.
\end{itemize}

\end{frame}

\beamerdefaultoverlayspecification{}

\begin{frame}{Distributive law for dot product}
\begin{align*}
f_{\bv}(\bu + \bw)
\uncover<2->{&= \bv \cdot (\bu + \bw) }\\
\uncover<3->{&=  \sum_i{v_i (u_i + w_i)} \\}
\uncover<4->{&= \sum_i{v_i u_i +v_i  w_i} \\}
\uncover<5->{&= \sum_i{v_i u_i} + \sum_i{v_i  w_i} \\}
\uncover<6->{&= \bv \cdot \bu + \bv \cdot \bw \\}
\uncover<7->{&= f_{\bv}(\bu) + f_{\bv}(\cdot \bw)}
\end{align*}

\end{frame}

\beamerdefaultoverlayspecification{<+->}

\begin{frame}{Dot Product is Linear (2)}

\begin{itemize}
\item So $f_{\bv}$ preserves vector addition.
\item Now we must show that $f_{\bv}$ preserves scalar multiplication.
\item Let $\bu \in \R^n$ and let $c\in\R$.
\item We must show $f_{\bv}(c \bu) = c f_{\bv}(\bu)$
\item i.e. that $\bv \cdot (c \bu) = c (\bv \cdot \bu)$
\end{itemize}

\end{frame}

\beamerdefaultoverlayspecification{}

\begin{frame}{Dot Product is Linear (3)}
\begin{align*}
f_{\bv}(c \bu)
\uncover<2->{&= \bv \cdot (c \bu) }\\
\uncover<3->{&=  \sum_i{v_i (c u_i)} \\}
\uncover<4->{&= c \sum_i{v_i u_i } \\}
\uncover<5->{&= c (\bv \cdot \bu) \\}
\uncover<5->{&= c f_{\bv}(\bu)}
\end{align*}

\end{frame}

\beamerdefaultoverlayspecification{<+->}

\begin{frame}{Dot Product is Linear (4)}

\begin{itemize}
\item So $f_{\bv}$ preserves scalar multiplication.
\item So $f_{\bv}$ is linear. $\qed$.
\end{itemize}

\end{frame}

\begin{frame}{Linear functions preserve linear combinations}
\begin{lemma}
Let $f:\R^n\map\R^m$. The following are equivalent:
\begin{enumerate}
\item $f$ is linear
\item $f$ preserves all linear combinations.

\pause

i.e. for every
$\bw_1,\bw_2,\cdots\bw_k\in\R^n$, for every $c_1,c_2,\cdots c_k\in\R$,
$$f(c_1 \bw_1 + c_2 \bw_2 + \cdots + c_k \bw_k) = c_1 f(\bw_1) + c_2 f(\bw_2) + \cdots + c_k f(\bw_k)$$

\pause

Using Sigma notation

$$f\left(\Sigma_{i=1}^k{c_i \bw_i}\right) = \Sigma_{i=1}^k{c_i f(\bw_i)}$$

\end{enumerate}
\end{lemma}
\end{frame}


\begin{frame}{Example: Covector preserves linear combinations}

\begin{itemize}
\item Let $\bv = (2, -1)$
\item So $f_{\bv}:\R^2 \map \R$.
\item Let $\bw_1 = (4, 5) \in \R^2$.
\item Let $\bw_2 = (1,-1) \in \R^2$.
\item $f_\bv(2\bw_1 -3\bw_2)$
\item $=f_\bv\bigl((5, 13)\bigr)$
\item $=\bv \cdot (5, 13)$
\item $=10 - 13 = -3$.
\item $2 f_{\bv}(\bw_1) -3 f_{\bv}(\bw_2)$
\item $= 2 (\bv \cdot \bw_1) -3 (\bv \cdot \bw_2)$
\item $=2 (3) - 3(3)$
\item $=-3$
\item So $f_\bv(2\bw_1 -3\bw_2) = 2f_{\bv}(\bw_1) -3 f_{\bv}(\bw_2)$.
\end{itemize}

\end{frame}

\begin{frame}{Proof of Lemma}

\begin{itemize}
\item First suppose that $f$ preserves all linear combinations
\item $f\left(\Sigma_{i=1}^k{c_i \bw_i}\right) = \Sigma_{i=1}^k{c_i f(\bw_i)}$
\item Letting $k=1$ we have
\item $f(c_1 \bw_1) = c_1 f(\bw_1)$.
\item So $f$ preserves scalar multiplication.
\item Letting $k=2$ and letting $c_1 = c_2 = 1$ we have
\item $f(\bw_1 + \bw_2) = f(\bw_1) + f(\bw_2)$.
\item So $f$ preserves vector addition.
\item Conversely, suppose $f$ preserves vector addition and scalar multiplication.
\item We must show that $f$ preserves all linear combinations.
\item This is done by induction on $k$.
\item The base case, $k=1$, says $f(c_1 \bw_1) = c_1 f(\bw_1)$.
\item This follows from the fact that $f$ preserves scalar multiplication.
\end{itemize}

\end{frame}

\beamerdefaultoverlayspecification{}

\begin{frame}{The inductive step}
Now suppose that
$$f\left(\Sigma_{i=1}^k{c_i \bw_i}\right) = \Sigma_{i=1}^k{c_i f(\bw_i)}$$

\smallskip

We must show that
$$f\left(\Sigma_{i=1}^{k+1}{c_i \bw_i}\right) = \Sigma_{i=1}^{k+1}{c_i f(\bw_i)}$$

\begin{align*}
&f\left(\Sigma_{i=1}^{k+1}{c_i \bw_i}\right)\\
\uncover<2->{&=  f\left(\Sigma_{i=1}^{k}{c_i \bw_i} + c_{k+1} \bw_{k+1}\right)\\}
\uncover<3->{&=  f\left(\Sigma_{i=1}^{k}{c_i \bw_i}\right) + f(c_{k+1} \bw_{k+1}) \text{ $f$ preserves addition} \\}
\uncover<4->{&= \Sigma_{i=1}^k{c_i f(\bw_i)} + f(c_{k+1} \bw_{k+1}) \text{ induction}\\}
\uncover<5->{&= \Sigma_{i=1}^k{c_i f(\bw_i)} + c_{k+1} f(\bw_{k+1}) \text{ $f$ preserves scalar mult.}\\}
\uncover<6->{&= \Sigma_{i=1}^{k+1}{c_i f(\bw_i)} }
\end{align*}

\uncover<7->{So $f$ preserves all linear combinations. $\qed$.}
\end{frame}

\beamerdefaultoverlayspecification{<+->}

\begin{frame}{Arbitrary functions are flexible}
\begin{itemize}
\item Suppose $f:\R^2\map\R$ is \emph{some} function. (Not necessarily linear).
\item Suppose I told you that $f(0,1) = 12$
\item and I told you that $f(1, 0) = -1$.
\item Question: What is $f(2, 2)$?
\item Answer: You have no idea. It could be anything.
\item Arbitrary functions are "flexible". They can bend however you want them to.
\item Knowing the value of $f$ at any finite number of points tells you nothing
about the value of $f$ at any other point.
\item Now suppose I told you $f$ were linear?
\item Then $f(2,2) = f\left(2(1,0) + 2(0,1)\right)$
\item $=2f(1,0) + 2f(0,1)$
\item $= 2(12) + 2 (-1) = 23$.
\end{itemize}
\end{frame}

\beamerdefaultoverlayspecification{}

\begin{frame}{Values at the standard basis vectors}

A linear function is determined by its values at the standard basis vectors.

\uncover<2->{
\begin{lemma}
Let $f:\R^n\map\R^m$ and $g:\R^n\map\R^m$  be two linear functions. \\
\uncover<3->{Suppose that $f(\be_i) = g(\be_i)$ for $i=1, 2, \cdots n$.} \\
\uncover<4->{Then $f = g$.}
\end{lemma}
}

\end{frame}

\begin{frame}{Proof of Lemma}

\begin{proof}
Assume $f(\be_i) = g(\be_i)$ for $i=1, 2, \cdots n$.
Let $\bv\in\R^n$ be any vector.
\uncover<2->{We must show that $f(\bv)=g(\bv)$.}
\uncover<3->{
Now $\bv = (v_1,v_2,\cdots v_n)$.
So $\bv=\sum_i{v_i \be_i}$.
}

\begin{align*}
\uncover<4->{f(\bv) &= f\left(\sum_i{v_i \be_i}\right) \\}
\uncover<5->{&= \sum_i{v_i f(\be_i)} \text{ \qquad (by linearity)}\\}
\uncover<6->{&= \sum_i{v_i g(\be_i)} \text { \qquad (by assumption)}\\}
\uncover<7->{&= g\left(\sum_i{v_i \be_i}\right) { \qquad  (by linearity)} \\}
\uncover<8->{&= g(\bv)}
\end{align*}
\end{proof}
\end{frame}

\beamerdefaultoverlayspecification{<+->}

\begin{frame}{All functionals are covectors}

All functionals on $\R^n$ are given by covectors.

\pause

\begin{lemma}
Let $f:\R^n\map\R$ be a covector.\\
\pause
Then there is a vector $\bv\in\R^n$ such that $f=f_{\bv}$. \\
\end{lemma}

\pause

\begin{itemize}
\item Proof:
\item Let $a_i = f(\be_i)$ for $i=1,\cdots n$.
\item Let $\bv=(a_1, a_2, \cdots a_n)$.
\item Notice $\bv\cdot\be_i=a_i$ for $i=1,\cdots n$.
\item So $f_{\bv}(\be_i)=a_i$ for $i=1,\cdots n$.
\item So $f_{\bv}(\be_i)=f(\be_i)$ for $i=1,\cdots n$.
\item By the previous lemma, $f = f_{\bv}$. $\qed$
\end{itemize}

\end{frame}

\begin{frame}{Linear component functions}

A function is linear iff it's component functions are.

\pause

\begin{lemma}
Let $f:\R^n\map\R^m$ be a function.\\
\pause
Write $f(\bv) = \left(f_1(\bv),f_2(\bv),\cdots f_m(\bv)\right)$. \\
\pause
Then the following are equivalent:
\pause
\begin{enumerate}
\item $f$ is linear
\item $f_i$ is linear for $i=1,\dots m$.
\end{enumerate}
\end{lemma}

\pause

\begin{itemize}
\item Proof:
\item Let $\bv_1,\dots\bv_n\in\R^n$ and let $c_1,\dots c_n \in\R$.
\item $f\left(\sum_j{c_j \bv_j}\right) = \sum_j{c_j f(\bv_j)}$
\item iff $\left(f_1\left(\sum_j{c_j \bv_j}\right),\cdots,f_m\left(\sum_j{c_j \bv_j}\right)\right) = \left( \sum_j{c_j f_1(\bv_j)},\cdots \sum_j{c_j f_m(\bv_j)} \right)$
\item iff $f_i\left(\sum_j{c_j \bv_j}\right) = \sum_j{c_j f_i(\bv_j)}$, for $i=1,\dots m$.
\end{itemize}

\end{frame}

\begin{frame}{Characterization of linear functions}

All linear functions from $\R^n$ to $\R^m$ are given by $m$ covectors.

\pause

\begin{theorem}
Let $f:\R^n\map\R^m$ be a linear function.\\
\pause
Then there are $m$ vectors $\bv_1,\bv_2,\cdots\bv_m \in \R^n$ such that
$f = \left(f_{\bv_1}, f_{\bv_2}, \cdots f_{\bv_n}\right)$.

\pause
\smallskip

Conversely, Let $\bv_1,\bv_2,\cdots\bv_m$ be any $m$ vectors in $\R^n$ and
let $f=\left(f_{\bv_1}, f_{\bv_2},\cdots f_{\bv_n}\right)$.
\pause
Then $f:\R^n\map\R^m$ is linear.

\end{theorem}

\end{frame}

\begin{frame}{Proof of theorem}

\begin{itemize}
\item Let $f:\R^n\map\R^m$ be a linear function.
\item Write $f = (f_1, f_2, \cdots f_m)$.
\item From a previous lemma each $f_i$ is linear.
\item But $f_i:\R^n\map\R$ so each $f_i$ is a linear functional.
\item But all linear functionals are covectors.
\item So for each $i$, let $\bv_i$ be such that $f_i = f_{\bv_i}$.
\item Then $f=(f_{\bv_1}, f_{\bv_2},\cdots f_{\bv_n})$.
\item Conversely, let $\bv_1,\bv_2,\cdots\bv_m$ be any $m$ vectors in $\R^n$.
\item Let $f=(f_{\bv_1}, f_{\bv_2},\cdots f_{\bv_n})$.
\item Since each of the component functions of $f$ is linear, $f$ is linear.
\end{itemize}


\end{frame}


\end{document}


