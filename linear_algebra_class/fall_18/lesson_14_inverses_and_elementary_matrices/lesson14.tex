% $Header$

\documentclass{beamer}
%\documentclass[handout]{beamer}

\usepackage{amsmath,amssymb,latexsym,eucal,amsthm,graphicx,xcolor}
\include{mathdefs}

\graphicspath{{images/}}

\newtheorem*{claim}{claim}
\newtheorem*{observation}{Observation}
\newtheorem*{warning}{Warning}
\newtheorem*{question}{Question}
\newtheorem{remark}[theorem]{Remark}

\newenvironment*{subproof}[1][Proof]
{\begin{proof}[#1]}{\renewcommand{\qedsymbol}{$\diamondsuit$} \end{proof}}

\mode<presentation>
{
  \usetheme{Singapore}
  % or ...

  \setbeamercovered{invisible}
  % or whatever (possibly just delete it)
}


\usepackage[english]{babel}
% or whatever

\usepackage[latin1]{inputenc}
% or whatever

\usepackage{times}
\usepackage[T1]{fontenc}
% Or whatever. Note that the encoding and the font should match. If T1
% does not look nice, try deleting the line with the fontenc.

\title{Lesson 14 \\ Inverses and Elementary Matrices}
\subtitle{Math 325, Linear Algebra \\ Fall 2018 \\ SFSU}
\author{Mitch Rudominer}
\date{}



% If you wish to uncover everything in a step-wise fashion, uncomment
% the following command:

\beamerdefaultoverlayspecification{<+->}

\begin{document}

\begin{frame}
  \titlepage
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Bound on the rank of a matrix}

\begin{itemize}
\item \textbf{Theorem.} Let $A$ be an $m\times n$ matrix.
\item Then $\rank(A) \leq n$
\item and $\rank(A) \leq m$.
\item \textbf{proof.} The rank of $A$ is the dimension of the subspace
of $\R^m$  spanned by the columns.
\item So it can't be larger than the dimension of $\R^m$, which is $m$.
\item And it can't be larger than the number of columns, which is $n$. $\qed$.
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Linear Bijections}

\begin{itemize}
\item \textbf{Theorem.} Let $A$ be an $m\times n$ matrix.
\item \textbf{(a)} $T_A$ is one-to-one iff $\rank(A) = n$.
\item \textbf{(b)} $T_A$ is onto $\R^m$ iff $\rank(A) = m$.
\item \textbf{(c)} $T_A$ is a bijection iff $n=m$, $A$ is a square $n\times n$ matrix, and $\rank(A) = n$.
\item \textbf{proof.} \textbf{(a)} We already know that $T_A$ is one-to-one iff the
columns of $A$ are linearly independent.
\item iff $\rank(A) = m$.
\item \textbf{(b)} $T_A$ is onto $\R^m$ iff $\dim(\ran(T_A)) = m$, iff $\rank(A) = m$.
\item \textbf{(c)} Follows immediately from (a) and (b). $\qed$
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Nonsingular Matrices}

\begin{itemize}
\item \textbf{Definition.} Let $A$ be a square $n\times n$ matrix.
\item $A$ is called \emph{nonsingular} or \emph{invertible} if $\rank(A)=n$.
\item Otherwise $A$ is called \emph{singular}.
\item \textbf{Theorem.} Let $A$ be a matrix. Then
\item $T_A^{-1}$ exists iff
\item $A$ is a square, nonsingular matrix.
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Inverses}

\begin{itemize}
\item \textbf{Theorem.} Let $V$ and $W$ be vector spaces and let
$T:V\map W$ be a linear transformation that is one-to-one and onto.
\item So $T^{-1}:W\map V$.
\item Then $T^{-1}$ is linear.
\item \textbf{proof.} Let $\bw_1,\bw_2$ be any two vectors in $W$ and let
$c\in\R$ be a scalar.
\item We must show that $T^{-1}(\bw_1+\bw_2) = T^{-1}(\bw_1) + T^{-1}(\bw_2)$
and $T^{-1}(c\bw_1) = cT^{-1}(\bw_1)$.
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Proof}

\begin{itemize}
\item Since $T$ is onto, let $\bv_1,\bv_2\in V$ be such that $T(\bv_1)=\bw_1$
and $T(\bv_2)=\bw_2$.
\item Since $T$ is linear $T(\bv_1+\bv_2)=\bw_1 + \bw_2$.
\item So, $T^{-1}(\bw_1+\bw_2) = \bv_1+\bv_2= T^{-1}(\bw_1) + T^{-1}(\bw_2)$.
\item Also, since $T$ is linear, $T(c\bv_1) = c\bw_1$.
\item So, $T^{-1}(c\bw_1) = c\bv_1 = cT^{-1}(\bw_1)$. $\qed$
\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Inverse matrices}

\begin{itemize}
\item \textbf{Theorem.} Let $A$ be a square $n\times n$ non-singular matrix.
\item  Then there exists another square $n\times n$ non-singular matrix $B$
such that $AB = BA = I$.
\item \textbf{proof}. We know that $T_A:\R^n\map\R^n$ is a bijection.
\item So $T_A^{-1}:\R^n\map\R^n$ exists.
\item We just learned in the previous theorem that $T_A^{-1}$ is linear.
\item So let $B$ be the matrix for $T_A^{-1}$.
\item Then $AB$ and $BA$ are both the matrices for the identity transformation.
\item So $AB=BA = I$. $\qed$.
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Impressive use of abstract theory}

\begin{itemize}
\item Let $$A=
\begin{pmatrix}
-11 & 17 &  41  &  -23 \\
 0  & -3 &   7  &   11 \\
 0 &  0  & -91  &   13 \\
 0 &  0  &   0  &   -41 \\
\end{pmatrix}
$$
\item We know that there must be some
$4\times 4$ matrix $B$ such that $AB=BA = I$.
\item At the moment we have no idea how we might go about finding such a $B$.
\item This is a triumph of abstract theory.

\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Inverse matrices}

\begin{itemize}
\item \textbf{Definition.} Let $A$ be any matrix.
\item Suppose there is another matrix $B$ such that $AB = BA = I$.
\item Then we say that $B$ is the \emph{inverse} of $A$, or $B$ is $A$-inverse,
and we write $B=A^{-1}$.
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{About inverse matrices}

\begin{itemize}
\item \textbf{Theorem.} Let $A$ be any matrix. Then
\item \textbf{(a)} $A^{-1}$ exists iff $A$ is a square, non-singular matrix.
\item Assuming $A^{-1}$ exists we have
\item \textbf{(b)} $A^{-1}$ is also a square matrix of the same size.
\item \textbf{(c)} $A^{-1}$ is the matrix for $T^{-1}_A$.
\item \textbf{(d)} $\left(A^{-1}\right)^{-1} = A$.
\item \textbf{(e)} $A^{-1}$ is unique.
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{proof}

\begin{itemize}
\item \textbf{proof.}
\item If $AB=I$ and $BA=I$ then $T_A\circ T_B$ and $T_B\circ T_A$ are both
the identitiy transformation.
\item So $T_A$ and $T_B$ are inverse functions, i.e. $T_B = T_A^{-1}$ and $T_A=T_B^{-1}$.
\item So $T_A$ and $T_B$ are both bijections.
\item By a previous theorem, this can only happen if $A$ and $B$ are non-singular
square matrices, and they must be of the same size since $AB$ and $BA$ are both defined.
\item $A^{-1}$ is unique because it is the matrix of $T_A^{-1}$.
\item $\left(A^{-1}\right)^{-1} = A$ because every function is the inverse of its inverse.
\item $\qed$
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{$AB=I$ is enough}

\begin{itemize}
\item \textbf{Theorem.} Let $A$  and $B$ be $n\times n$ matrices.
\item Suppose $AB=I$.
\item Then $A$ and $B$ are inverses.
\item In other words, you don't need to check that $BA=I$.
\item \textbf{proof.} First notice that $B$ is invertible.
\item To see this suppose $B\bv=\bzero$. Multiply both sides on the left by $A$.
\item $AB\bv=A\bzero\quad \implies \quad I\bv = \bzero \quad \implies \quad \bv = \bzero$.
\item So $\ker(T_B)=\singleton{\bzero}$. So $B$ is invertible. So $B^{-1}$ exists and is $n\times n$.
\item $AB=I$. Multiply both sides  on the right by $B^{-1}$.
\item $ABB^{-1} = I B^{-1} \quad \implies \quad A I = B^{-1}\quad \implies \quad  A  = B^{-1}$. $\qed$
\end{itemize}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Inverting the action of a matrix}

\begin{itemize}
\item Let $A$ be an invertible matrix. How do we find $A^{-1}$?
\item One way to find the inverse of a matrix is to think about
about its linear transformation as an \emph{action} on vectors.
\item Understand what the matrix does to vectors and try to find
a matrix that does the inverse of that.
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{The inverse of a diagonal matrix}

\begin{itemize}
\item Example: Let
$$
A =
\begin{pmatrix}
2 & 0 & 0 \\
0 & -3 & 0 \\
0 & 0 & 4 \\
\end{pmatrix}
$$
\item Decide if $A$ is invertible and if so find $A^{-1}$.
\item Let's understand the action of $A$ on vectors.
\item Consider
$$
\begin{pmatrix}
2 & 0 & 0 \\
0 & -3 & 0 \\
0 & 0 & 4 \\
\end{pmatrix}
\begin{pmatrix}
x \\ y \\ z
\end{pmatrix}
=
\begin{pmatrix}
2x \\ -3y \\ 4z
\end{pmatrix}
$$
\item What does $A$ do to a vector $\bv$?
\item It multiplies the first component by 2, the second component by -3
and the third component by 4.
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{The inverse action}

\begin{itemize}
\item Let
$$
A =
\begin{pmatrix}
2 & 0 & 0 \\
0 & -3 & 0 \\
0 & 0 & 4 \\
\end{pmatrix}
$$
\item What action must $A^{-1}$ do to a vector?
\item It must multiply the first component by $\frac{1}{2}$, the second component by
$\frac{-1}{3}$  and the third component by $\frac{1}{4}$.
\item So we must have that
$$
A^{-1} =
\begin{pmatrix}
\frac{1}{2} & 0 & 0 \\
0 & \frac{-1}{3} & 0 \\
0 & 0 & \frac{1}{4} \\
\end{pmatrix}
$$
\item Check
$$
\begin{pmatrix}
2 & 0 & 0 \\
0 & -3 & 0 \\
0 & 0 & 4 \\
\end{pmatrix}
\begin{pmatrix}
\frac{1}{2} & 0 & 0 \\
0 & \frac{-1}{3} & 0 \\
0 & 0 & \frac{1}{4} \\
\end{pmatrix}
=
\begin{pmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1 \\
\end{pmatrix}
$$
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Diagonal matrix with a zero}

\begin{itemize}
\item Example: Let
$$
B =
\begin{pmatrix}
2 & 0 & 0 \\
0 & 0 & 0 \\
0 & 0 & 4 \\
\end{pmatrix}
$$
\item Decide if $A$ is invertible and if so find $A^{-1}$.
\item Let's understand the action of $A$ on vectors.
\item Consider
$$
\begin{pmatrix}
2 & 0 & 0 \\
0 & 0 & 0 \\
0 & 0 & 4 \\
\end{pmatrix}
\begin{pmatrix}
x \\ y \\ z
\end{pmatrix}
=
\begin{pmatrix}
2x \\ 0 \\ 4z
\end{pmatrix}
$$
\item What does $A$ do to a vector $\bv$?
\item It multiplies the first component by 2, the second component by 0
and the third component by 4.
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Undoing the action}

\begin{itemize}
\item Can we find a matrix that can undo the action of the matrix
$$
\begin{pmatrix}
2 & 0 & 0 \\
0 & 0 & 0 \\
0 & 0 & 4 \\
\end{pmatrix}
?
$$
\item No we cannot.
\item Because multiplying by zero is not invertible.
\item Multiplying by 0 is not one-to-one.
\item $B$ is not invertible.
\item We can also see that because the columns of $B$ are not
linearly independent since one of the columns is the zero vector.
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Inverses of diagonal matrics}

\begin{itemize}
\item \textbf{Theorem.} Let $D=\diag(d_1,d_2,\cdots,d_n)$
be a diagonal $n\times n$ matrix.
\item If any of the $d_i$ are zero then $D$ is singular (non-inveritble.)
\item If all of the $d_i$ are nonzero then $D$ is nonsingular (inveritble)
and the inverse of $D$ is
\item $D^{-1}=\diag(1/d_1,1/d_2,\cdots,1/d_n)$
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Elementary matrices}

\begin{itemize}
\item \emph{Elementary} matrices are invertible matrices whose actions
are particularly simple.
\item There are three types of elementary matrices: types I, II and III.
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Elementary matrices of type I}

\begin{itemize}
\item \textbf{Definition.} An elementary matrix of \emph{type I} is a square
matrix whose action on vectors is: Add c times row i to row j, for some fixed
i, j, $c\not=0$.
\item To find the matrix that does this, perform that action on the
rows of the identity matrix.
\item Find the $3\times 3$ matrix that adds -2 times row 2 to row 3.
\item Add -2 times row 2 of the identity matrix to row 3 of the identity matrix.
\item $
E = \begin{pmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & -2 & 1 \\
\end{pmatrix}
$
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Elementary matrices of type I}

\begin{itemize}
\item Compute $
\begin{pmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & -2 & 1 \\
\end{pmatrix}
\begin{pmatrix}
x \\
y \\
z  \\
\end{pmatrix}
$
\item
$
\begin{pmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & -2 & 1 \\
\end{pmatrix}
\begin{pmatrix}
x \\
y \\
z  \\
\end{pmatrix}
=
\begin{pmatrix}
x \\
y \\
z -2y \\
\end{pmatrix}
$
\item Compute $
\begin{pmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & -2 & 1 \\
\end{pmatrix}
\begin{pmatrix}
3 \\
4 \\
5  \\
\end{pmatrix}
=
\begin{pmatrix}
3 \\
4 \\
-3 \\
\end{pmatrix}
$

\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{The Inverse of an Elementary Matrix of type I}

\begin{itemize}
\item Let $E=
\begin{pmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & -2 & 1 \\
\end{pmatrix}
$
\item To find $E^{-1}$, consider the action which will undo the action
of $E$.
\item Add 2 times row 2 to row 3.
\item $E^{-1}=
\begin{pmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 2 & 1 \\
\end{pmatrix}
$
\item Compute $
\begin{pmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 2 & 1 \\
\end{pmatrix}
\begin{pmatrix}
3 \\
4 \\
-3  \\
\end{pmatrix}
=
\begin{pmatrix}
3 \\
4 \\
5 \\
\end{pmatrix}
$
\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Check the inverse}

\begin{itemize}
\item Let $E=
\begin{pmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & -2 & 1 \\
\end{pmatrix}
$
\item Check
\item $
\begin{pmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & -2 & 1 \\
\end{pmatrix}
\begin{pmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 2 & 1 \\
\end{pmatrix}
=
\begin{pmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1 \\
\end{pmatrix}
$
\item So $E^{-1}=
\begin{pmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 2 & 1 \\
\end{pmatrix}
$
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{More Elementary Matrices of type I}

\begin{itemize}
\item An elementary matrix of type I:
\item Is a square $n\times n$ matrix,
\item with ones on the diagonal,
\item and zeros in every other position except for one entry $c\not=0$ in position $(i,j)$ for some $i\not=j$.
\item The action of this matrix is to replace row $i$ with row $i$ plus $c$ times row $j$.
\item The inverse matrix has $-c$ in position $(i,j)$.
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Example Elementary Matrices of type I}

\begin{itemize}
\item Let $E$ be the $4\times 4$ elementary matrix of type I that adds 3 times row 4 to row 2.
\item write down $E$ and $E^{-1}$.
\item
$
E=
\begin{pmatrix}
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 3 \\
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1 \\
\end{pmatrix}
$
\item
Compute
$
\begin{pmatrix}
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 3 \\
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1 \\
\end{pmatrix}
\begin{pmatrix}
1  \\
2  \\
3  \\
4  \\
\end{pmatrix}
=
\begin{pmatrix}
1  \\
14  \\
3  \\
4  \\
\end{pmatrix}
$
\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Example Inverse of Elementary Matrices of type I}

\begin{itemize}

\item
$
E^{-1}=
\begin{pmatrix}
1 & 0 & 0 & 0 \\
0 & 1 & 0 & -3 \\
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1 \\
\end{pmatrix}
$
\item Compute
$
\begin{pmatrix}
1 & 0 & 0 & 0 \\
0 & 1 & 0 & -3 \\
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1 \\
\end{pmatrix}
\begin{pmatrix}
1  \\
14  \\
3  \\
4  \\
\end{pmatrix}
=
\begin{pmatrix}
1  \\
2  \\
3  \\
4  \\
\end{pmatrix}
$
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Elementary Matrices Operate on Matrices}

\begin{itemize}
\item Let $E$ be an $n\times n$ elementary matrix of type I.
\item We can also think of $E$ as performing a row operation on other matrices.
\item Let $A$ be any other $n\times n$ matrix.
\item Then $EA$ is the matrix that results from performing the action of $E$
on the rows of $A$.
\end{itemize}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Example: Elementary Matrices Operate on Matrices}

\begin{itemize}
\item Let $E=
\begin{pmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & -2 & 1 \\
\end{pmatrix}
$
\item Let $A=
\begin{pmatrix}
1 & 2 & 3 \\
4 & 5 & 6 \\
7 & 8 & 9 \\
\end{pmatrix}
$
\item Then $EA=
\begin{pmatrix}
1 & 2 & 3 \\
4 & 5 & 6 \\
-1 & -2 & -3 \\
\end{pmatrix}
$
\item $EA$ is the result of replacing row 3 of $A$ with row 3 plus -2 times row 2.
\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Example: Inverse Elementary Matrices Operate on Matrices}

\begin{itemize}
\item Of course $E^{-1}\left(EA\right) = A$
\item $
\begin{pmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 2 & 1 \\
\end{pmatrix}
\begin{pmatrix}
1 & 2 & 3 \\
4 & 5 & 6 \\
-1 & -2 & -3 \\
\end{pmatrix}
=
\begin{pmatrix}
1 & 2 & 3 \\
4 & 5 & 6 \\
7 & 8 & 9 \\
\end{pmatrix}
$
\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Elementary matrices of type II}

\begin{itemize}
\item \textbf{Definition.} An elementary matrix of \emph{type II} is a square
matrix whose action on vectors and matrices is: Swap rows i and j
\item To find the matrix that does this, perform that action on the
rows of the identity matrix.
\item Find the $3\times 3$ matrix that swaps rows 2 and 3.
\item Swap row 2 and 3 of the identity matrix.
\item $
E = \begin{pmatrix}
1 & 0 & 0 \\
0 & 0 & 1 \\
0 & 1 & 0 \\
\end{pmatrix}
$
\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Elementary matrices of type II}

\begin{itemize}
\item Compute $
\begin{pmatrix}
1 & 0 & 0 \\
0 & 0 & 1 \\
0 & 1 & 0 \\
\end{pmatrix}
\begin{pmatrix}
x \\
y \\
z  \\
\end{pmatrix}
$
\item
$
\begin{pmatrix}
1 & 0 & 0 \\
0 & 0 & 1 \\
0 & 1 & 0 \\
\end{pmatrix}
\begin{pmatrix}
x \\
y \\
z  \\
\end{pmatrix}
=
\begin{pmatrix}
x \\
z \\
y \\
\end{pmatrix}
$
\item
$
\begin{pmatrix}
1 & 0 & 0 \\
0 & 0 & 1 \\
0 & 1 & 0 \\
\end{pmatrix}
\begin{pmatrix}
1 & 2 & 3 \\
4 & 5 & 6 \\
7 & 8 & 9 \\
\end{pmatrix}
=
\begin{pmatrix}
1 & 2 & 3 \\
7 & 8 & 9 \\
4 & 5 & 6 \\
\end{pmatrix}
$

\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{The Inverse of an Elementary Matrix of type II}

\begin{itemize}
\item Let $E=
\begin{pmatrix}
1 & 0 & 0 \\
0 & 0 & 1 \\
0 & 1 & 0 \\
\end{pmatrix}
$
\item To find $E^{-1}$, consider the action which will undo the action
of $E$.
\item $E$ is its own inverse. $E^2=I$.
\item $E=E^{-1}$.
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Permutation Matrices}

\begin{itemize}
\item Elementary matrices of type II are a special case of permutation matrices.
\item \textbf{Definition.} A \emph{permuation matrix} is a matrix whose action
is to permute rows.
\item Find the permutation matrix whose action is to perform the following
permutation on rows $(1,2,3) \mapsto (3,1,2)$.
\item Apply this permutation to the rows of the identity matrix.
\item $
\begin{pmatrix}
0 & 0 & 1 \\
1 & 0 & 0 \\
0 & 1 & 0 \\
\end{pmatrix}
$
\item
$
\begin{pmatrix}
0 & 0 & 1 \\
1 & 0 & 0 \\
0 & 1 & 0 \\
\end{pmatrix}
\begin{pmatrix}
 a \\
 b \\
 c \\
\end{pmatrix}
=
\begin{pmatrix}
 c \\
 a \\
 b \\
\end{pmatrix}
$
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Permutation Matrices}

\begin{itemize}
\item A permuation matrix is a matrix containing
only zeros and ones, where each row and each column contains exactly one one.
\item Every permutation matrix can be expressed as the product of elementary
matrices of type II.
\item $
\begin{pmatrix}
0 & 0 & 1 \\
1 & 0 & 0 \\
0 & 1 & 0 \\
\end{pmatrix}
=
\begin{pmatrix}
0 & 1 & 0 \\
1 & 0 & 0 \\
0 & 0 & 1 \\
\end{pmatrix}
\begin{pmatrix}
1 & 0 & 0 \\
0 & 0 & 1 \\
0 & 1 & 0 \\
\end{pmatrix}
$
\item How do we find the inverse of
$
\begin{pmatrix}
0 & 0 & 1 \\
1 & 0 & 0 \\
0 & 1 & 0 \\
\end{pmatrix}
$?
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{The Inverse of a Product}

\begin{itemize}
\item \textbf{Theorem.} Let $A$ and $B$ be invertible $n\times n$ matrices.
\item Then $AB$ is invertible and $\left(AB\right)^{-1} = B^{-1} A^{-1}$.
\item \textbf{proof} $\left(AB\right)\left(B^{-1} A^{-1}\right)$
\item $= A(B B^{-1})A^{-1}$
\item $= A A^{-1}$
\item $=I$.
\item so $(AB)^{-1} = B^{-1} A^{-1}$. $\qed$.
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Example. The Product of two elementary permutations.}

\begin{itemize}
\item Suppose $E_1$ and $E_2$ are elementatary matrices of type II and
$P=E_1 E_2$ is a permutation matrix.
\item Then $P^{-1} = E_2^{-1} E_1^{-1} = E_2 E_1$.
\item $
\begin{pmatrix}
0 & 0 & 1 \\
1 & 0 & 0 \\
0 & 1 & 0 \\
\end{pmatrix}
=
\begin{pmatrix}
0 & 1 & 0 \\
1 & 0 & 0 \\
0 & 0 & 1 \\
\end{pmatrix}
\begin{pmatrix}
1 & 0 & 0 \\
0 & 0 & 1 \\
0 & 1 & 0 \\
\end{pmatrix}
$
\item The inverse of the permutation matrix on the left is
$
\begin{pmatrix}
1 & 0 & 0 \\
0 & 0 & 1 \\
0 & 1 & 0 \\
\end{pmatrix}
\begin{pmatrix}
0 & 1 & 0 \\
1 & 0 & 0 \\
0 & 0 & 1 \\
\end{pmatrix}=
\begin{pmatrix}
0 & 1 & 0 \\
0 & 0 & 1 \\
1 & 0 & 0 \\
\end{pmatrix}
$
\item Check
$
\begin{pmatrix}
0 & 0 & 1 \\
1 & 0 & 0 \\
0 & 1 & 0 \\
\end{pmatrix}
\begin{pmatrix}
0 & 1 & 0 \\
0 & 0 & 1 \\
1 & 0 & 0 \\
\end{pmatrix}=
\begin{pmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1 \\
\end{pmatrix}.
$
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Elementary matrices of type III}

\begin{itemize}
\item \textbf{Definition.} An elementary matrix of \emph{type III} is a square
matrix whose action on vectors and matrices is: Multiply row $i$ by $c$.
\item Find the $3\times 3$ matrix that multiplies row 3 by -5.
\item Multiply row 3 of the identity matrix by -5.
\item $
E = \begin{pmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & -5 \\
\end{pmatrix}
$
\item This is just a special case of a diagonal matrix with nonzero entries.
\item $
E^{-1} = \begin{pmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & -1/5 \\
\end{pmatrix}
$
\end{itemize}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Towards the Inverse of a $2\times 2$ Matrix}

\begin{itemize}
\item Let
$A=
\begin{pmatrix}
a & b  \\
c & d  \\
\end{pmatrix}
$
be any $2\times 2$ matrix.
\item Consider the matrix
$B=
\begin{pmatrix}
 d & -b\\
-c & a \\
\end{pmatrix}
$
\item Compute $AB$.
\item $
\begin{pmatrix}
a & b  \\
c & d  \\
\end{pmatrix}
\begin{pmatrix}
 d & -b\\
-c & a \\
\end{pmatrix}
=
\begin{pmatrix}
 ad-bc & 0\\
0 & ad-bc \\
\end{pmatrix}
$
\item $=(ad-bc)
\begin{pmatrix}
 1 & 0\\
0 & 1 \\
\end{pmatrix}
$
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{The Determinant of a $2\times 2$ Matrix}

\begin{itemize}
\item Let
$A=
\begin{pmatrix}
a & b  \\
c & d  \\
\end{pmatrix}
$
be any $2\times 2$ matrix.
\item The number $ad-bc$ is called the \emph{determinant} of $A$, written $\det(A)$ or $\left | A \right |$.
\item Square matrices of all sizes have determinants. We will learn about
determinants for larger square matrices later.
\item Determinants play an important role in the theory of Linear Algebra.
\item The determinant of a matrix is a single number that gives us some information
about the whole matrix.
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{The Determinant and the Inverse}

\begin{itemize}
\item Let
$A=
\begin{pmatrix}
a & b  \\
c & d  \\
\end{pmatrix}
\text{, }
B=
\begin{pmatrix}
d & -b  \\
-c & a  \\
\end{pmatrix}.
$
\item Two slides ago we computed
$AB = \det(A)
\begin{pmatrix}
1 & 0  \\
0 & 1  \\
\end{pmatrix}
$.
\item \textbf{Theorem.} $A$ is invertible iff $\det(A)\not=0$.
\item If $A$ is invertible then
$$A^{-1} = \frac{1}{\det(A)}
\begin{pmatrix}
d & -b  \\
-c & a  \\
\end{pmatrix}
$$
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Proof}

\begin{itemize}
\item \textbf{Proof.} Let
$A=
\begin{pmatrix}
a & b  \\
c & d  \\
\end{pmatrix}
\text{, }
B=
\begin{pmatrix}
d & -b  \\
-c & a  \\
\end{pmatrix}.
$
\item So
$AB = \det(A)
\begin{pmatrix}
1 & 0  \\
0 & 1  \\
\end{pmatrix}
$.
\item If $\det(A)\not=0$, then we can divide by it and get that
$$A \left ( \frac{1}{\det(A)}B \right) = I.$$
\item So $A^{-1} = \frac{1}{\det(A)}B$.
\item So $A$ is invertible.
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Proof}

\begin{itemize}
\item \textbf{Proof continued.} We have
$A=
\begin{pmatrix}
a & b  \\
c & d  \\
\end{pmatrix}
\text{, }
B=
\begin{pmatrix}
d & -b  \\
-c & a  \\
\end{pmatrix}.
$
\item and
$AB = \det(A)
\begin{pmatrix}
1 & 0  \\
0 & 1  \\
\end{pmatrix}
$.
\item If $\det(A)=0$ then we have $AB=O$.
\item Let $\bv_1,\bv_2$ be the columns of $B$.
\item So $A\bv_1 = \bzero$ and $A\bv_2 = \bzero$.
\item If $\bv_1=\bv_2=\bzero$ then $B=O$ and so $A=O$ and
so $A$ is not invertible.
\item So assume one of $\bv_1$ or $\bv_2$ is not zero.
\item But they are in $\ker(A)$.
\item So $\ker(A)$ is not trivial.
\item So $A$ is not invertible. $\qed$.
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Example}

\begin{itemize}
\item Compute the determinant of $A$. Say whether or not $A$ is invertible
and if so give its inverse.
\item
$
A =
\begin{pmatrix}
1 & 2 \\
3 & 4 \\
\end{pmatrix}
$
\item $\det(A) = 4 - 6 = -2$.
\item $A$ is invertible.
\item $
A^{-1} =
(-1/2)
\begin{pmatrix}
4 & -2 \\
-3 & 1 \\
\end{pmatrix}
=
\begin{pmatrix}
-2 & 1 \\
\frac{3}{2} & -\frac{1}{2} \\
\end{pmatrix}
$
\item Check
$
\begin{pmatrix}
1 & 2 \\
3 & 4 \\
\end{pmatrix}
\begin{pmatrix}
-2 & 1 \\
\frac{3}{2} & -\frac{1}{2} \\
\end{pmatrix}
$
\item
$
= (-1/2)
\begin{pmatrix}
1 & 2 \\
3 & 4 \\
\end{pmatrix}
\begin{pmatrix}
4 & -2 \\
-3 & 1 \\
\end{pmatrix}
=
(-1/2)
\begin{pmatrix}
-2 & 0 \\
0 & -2\\
\end{pmatrix}
=
\begin{pmatrix}
1 & 0 \\
0 & 1\\
\end{pmatrix}
$
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Example}

\begin{itemize}
\item Compute the determinant of $A$. Say whether or not $A$ is invertible
and if so give its inverse.
\item
$
A =
\begin{pmatrix}
1 & 2 \\
3 & 6 \\
\end{pmatrix}
$
\item $\det(A) = 6 - 6 = 0$.
\item $A$ is not invertible.
\end{itemize}
\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\end{document}


